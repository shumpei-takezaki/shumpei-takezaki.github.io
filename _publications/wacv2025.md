---
title: "Consistent Diffusion Models: Mitigating Sampling Drift by Learning to be Consistent"
collection: publications
category: manuscripts
permalink: /publication/cdm
excerpt: ''
status: 'Published'
venue: 'WACV 2025'
authors: '<strong> Shumpei Takezaki</strong>, Kiyohito Tanaka, Seiichi Uchida'
paperurl: https://arxiv.org/abs/2410.21885
code: https://github.com/shumpei-takezaki/Self-Relaxed-Joint-Training
date: 2025-03-12
---

![](../images/wacv2025_overview.png)
(Image source: [On the Equivalence of Consistency-Type Models](https://arxiv.org/pdf/2410.21885))

> Severity level estimation is a crucial task in medical image diagnosis. However, accurately assigning severity class labels to individual images is very costly and challenging. Consequently, the attached labels tend to be noisy. In this paper, we propose a new framework for training with ``ordinal'' noisy labels. Since severity levels have an ordinal relationship, we can leverage this to train a classifier while mitigating the negative effects of noisy labels. Our framework uses two techniques: clean sample selection and dual-network architecture. A technical highlight of our approach is the use of soft labels derived from noisy hard labels. By appropriately using the soft and hard labels in the two techniques, we achieve more accurate sample selection and robust network training. The proposed method outperforms various state-of-the-art methods in experiments using two endoscopic ulcerative colitis (UC) datasets.

Please read the [paper](https://arxiv.org/abs/2410.21885) for more details.
